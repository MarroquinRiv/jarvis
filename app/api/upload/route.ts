import { NextRequest, NextResponse } from "next/server";
import { createClient } from "@supabase/supabase-js";
import OpenAI from "openai";
import mammoth from "mammoth";
import * as XLSX from "xlsx";
import { parse } from "csv-parse/sync";

// Inicializar Supabase con Service Role Key
const supabaseUrl = process.env.NEXT_PUBLIC_SUPABASE_URL!;
const supabaseServiceKey = process.env.SUPABASE_SERVICE_ROLE_KEY!;

if (!supabaseUrl || !supabaseServiceKey) {
  throw new Error("Missing Supabase configuration");
}

const supabaseClient = createClient(supabaseUrl, supabaseServiceKey, {
  auth: {
    persistSession: false,
    autoRefreshToken: false,
  },
});

// Inicializar OpenAI Client
const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY!,
});

// Funci√≥n para dividir texto en chunks
function splitTextIntoChunks(
  text: string,
  chunkSize: number = 1000,
  overlap: number = 200
): string[] {
  const chunks: string[] = [];
  let startIndex = 0;

  while (startIndex < text.length) {
    const endIndex = startIndex + chunkSize;
    const chunk = text.slice(startIndex, endIndex);
    chunks.push(chunk);

    // Move forward, accounting for overlap
    startIndex += chunkSize - overlap;
  }

  return chunks;
}

// Funciones de extracci√≥n de texto por tipo de archivo
async function extractTextFromPDF(buffer: Buffer): Promise<string> {
  try {
    // Validar que el buffer no est√© vac√≠o
    if (!buffer || buffer.length === 0) {
      throw new Error("Buffer del PDF est√° vac√≠o");
    }

    console.log(`üìä Tama√±o del buffer PDF: ${buffer.length} bytes`);

    // Usar pdfjs-dist (Mozilla) en lugar de pdf-parse
    const pdfjsLib = require("pdfjs-dist/legacy/build/pdf.js");
    
    // Cargar el PDF desde el buffer
    const loadingTask = pdfjsLib.getDocument({
      data: new Uint8Array(buffer),
      useSystemFonts: true,
    });

    const pdfDocument = await loadingTask.promise;
    const numPages = pdfDocument.numPages;
    console.log(`üìÑ PDF tiene ${numPages} p√°ginas`);

    let fullText = "";

    // Extraer texto de cada p√°gina
    for (let pageNum = 1; pageNum <= numPages; pageNum++) {
      const page = await pdfDocument.getPage(pageNum);
      const textContent = await page.getTextContent();
      const pageText = textContent.items
        .map((item: any) => item.str)
        .join(" ");
      fullText += pageText + "\n";
    }

    if (!fullText || fullText.trim().length === 0) {
      throw new Error("No se pudo extraer texto del PDF");
    }

    console.log(`‚úÖ PDF procesado: ${numPages} p√°ginas, ${fullText.length} caracteres`);
    return fullText;
  } catch (error: any) {
    console.error("‚ùå Error en extractTextFromPDF:", error);
    throw new Error(`Error extrayendo texto del PDF: ${error.message}`);
  }
}

async function extractTextFromWord(buffer: Buffer): Promise<string> {
  const result = await mammoth.extractRawText({ buffer });
  return result.value;
}

async function extractTextFromExcel(buffer: Buffer): Promise<string> {
  const workbook = XLSX.read(buffer, { type: "buffer" });
  let text = "";
  
  workbook.SheetNames.forEach((sheetName) => {
    const sheet = workbook.Sheets[sheetName];
    const csv = XLSX.utils.sheet_to_csv(sheet);
    text += `\n--- ${sheetName} ---\n${csv}\n`;
  });
  
  return text;
}

async function extractTextFromCSV(buffer: Buffer): Promise<string> {
  const content = buffer.toString("utf-8");
  const records = parse(content, {
    skip_empty_lines: true,
    trim: true,
  });
  
  return records.map((row: any) => row.join(", ")).join("\n");
}

async function extractTextFromText(buffer: Buffer): Promise<string> {
  return buffer.toString("utf-8");
}

// Funci√≥n principal de extracci√≥n
async function extractText(file: File): Promise<string> {
  try {
    console.log(`üìÅ Archivo recibido: ${file.name} (${file.size} bytes, tipo: ${file.type})`);

    // Validar que el archivo tenga contenido
    if (file.size === 0) {
      throw new Error("El archivo est√° vac√≠o");
    }

    const arrayBuffer = await file.arrayBuffer();
    const buffer = Buffer.from(arrayBuffer);

    console.log(`üîÑ Buffer creado: ${buffer.length} bytes`);

    const extension = file.name.split(".").pop()?.toLowerCase();
    console.log(`üìé Extensi√≥n detectada: ${extension}`);

    switch (extension) {
      case "pdf":
        return await extractTextFromPDF(buffer);
      case "docx":
        return await extractTextFromWord(buffer);
      case "xlsx":
        return await extractTextFromExcel(buffer);
      case "csv":
        return await extractTextFromCSV(buffer);
      case "txt":
      case "md":
        return await extractTextFromText(buffer);
      case "pptx":
        throw new Error("PowerPoint (.pptx) a√∫n no soportado completamente");
      default:
        throw new Error(`Formato no soportado: ${extension}`);
    }
  } catch (error: any) {
    console.error("‚ùå Error en extractText:", error);
    throw error; // Re-lanzar para que sea capturado por el handler principal
  }
}

export async function POST(request: NextRequest) {
  try {
    // Obtener el archivo del FormData
    const formData = await request.formData();
    const file = formData.get("file") as File;
    
    if (!file) {
      return NextResponse.json(
        { error: "No se proporcion√≥ ning√∫n archivo" },
        { status: 400 }
      );
    }

    console.log(`üìÑ Procesando archivo: ${file.name}`);

    // 1. Extraer texto del documento
    console.log("üîç Extrayendo texto...");
    const text = await extractText(file);
    
    if (!text || text.trim().length === 0) {
      return NextResponse.json(
        { error: "No se pudo extraer texto del documento" },
        { status: 400 }
      );
    }

    console.log(`üìù Texto extra√≠do: ${text.length} caracteres`);

    // 2. Dividir en chunks
    console.log("‚úÇÔ∏è  Dividiendo en chunks...");
    const chunks = splitTextIntoChunks(text);
    console.log(`üì¶ Creados ${chunks.length} chunks`);

    // 3. Crear metadata base
    const baseMetadata = {
      source: file.name,
      blobType: file.type,
      uploadedAt: new Date().toISOString(),
    };

    // 4. Procesar cada chunk: generar embedding e insertar
    console.log("üß† Generando embeddings y guardando en Supabase...");
    let insertedChunks = 0;

    for (let i = 0; i < chunks.length; i++) {
      const chunk = chunks[i];
      
      // Crear metadata espec√≠fico del chunk
      const chunkMetadata = {
        ...baseMetadata,
        loc: { pageNumber: i + 1 },
        chunkIndex: i,
        totalChunks: chunks.length,
      };

      // Generar embedding para este chunk usando OpenAI API directamente
      let embeddingVector: number[];
      
      try {
        const embeddingResponse = await openai.embeddings.create({
          model: "text-embedding-3-small",
          input: chunk,
        });
        embeddingVector = embeddingResponse.data[0].embedding;
      } catch (openaiError: any) {
        console.error(`‚ùå Error de OpenAI:`, openaiError);
        
        // Si es error 429 (quota), devolver error espec√≠fico
        if (openaiError.status === 429 || openaiError.code === 'insufficient_quota') {
          return NextResponse.json(
            { 
              error: "El servicio de embeddings est√° temporalmente no disponible. Por favor, contacta al administrador.",
              details: "OpenAI quota exceeded"
            },
            { status: 503 }
          );
        }
        
        throw new Error(`Error generando embedding: ${openaiError.message}`);
      }

      // Insertar en Supabase
      const { error } = await supabaseClient
        .from("documents")
        .insert({
          content: chunk,
          metadata: chunkMetadata,
          embedding: embeddingVector,
        });

      if (error) {
        console.error(`‚ùå Error insertando chunk ${i}:`, error);
        throw new Error(`Error al guardar chunk ${i}: ${error.message}`);
      }

      insertedChunks++;
      console.log(`‚úÖ Chunk ${i + 1}/${chunks.length} guardado`);
    }

    console.log(`‚úÖ Documento procesado exitosamente: ${insertedChunks} chunks guardados`);

    return NextResponse.json({
      success: true,
      fileName: file.name,
      chunks: insertedChunks,
      message: "Documento procesado y guardado exitosamente",
    });

  } catch (error: any) {
    console.error("‚ùå Error procesando documento:", error);
    return NextResponse.json(
      { error: error.message || "Error al procesar el documento" },
      { status: 500 }
    );
  }
}
